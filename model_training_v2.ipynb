{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[160:260, 50:250])\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    \n",
    "    frames = tf.cast(frames, tf.float32)\n",
    "    mean = tf.cast(mean, tf.float32)\n",
    "    \n",
    "    result = (frames - mean)/ std\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "\n",
    "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]:\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil':\n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    path = bytes.decode(path.numpy())\n",
    "    file_name = path.split(\"\\\\\")[-1].split('.')[0]\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "\n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path:str) -> List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files(r'data\\s1\\*.mpg')\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(None, 100, 200, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):\n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, None, 100, 200, 1  3584      \n",
      "                             28)                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, 100, 200, 1  0         \n",
      "                             28)                                 \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, None, 50, 100, 12  0        \n",
      " )                           8)                                  \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, None, 50, 100, 25  884992    \n",
      "                             6)                                  \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, 50, 100, 25  0         \n",
      "                             6)                                  \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, None, 25, 50, 256  0        \n",
      " 3D)                         )                                   \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, None, 25, 50, 75)  518475    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, 25, 50, 75)  0         \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, None, 12, 25, 75)  0        \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 22500)      0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 256)        23172096  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 256)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, None, 256)        394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 256)         0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 41)          10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,983,924\n",
      "Trainable params: 24,983,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)\n",
    "schedule_callback = LearningRateScheduler(scheduler)\n",
    "example_callback = ProduceExample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/steps - loss: 84.01\n",
      "Original: bin red in f five soon\n",
      "Prediction: le e e e e en\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red by j five soon\n",
      "Prediction: le e e e e en\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 481s 1s/step - loss: 84.0151 - val_loss: 70.4480 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 73ms/step- loss: 70.97\n",
      "Original: lay white in e six please\n",
      "Prediction: la e e e e eo\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin green at t eight now\n",
      "Prediction: la e e e e eo\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 337s 749ms/step - loss: 70.9756 - val_loss: 65.9705 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 72ms/step- loss: 67.55\n",
      "Original: place white by k three again\n",
      "Prediction: la e e t e eo\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin blue in l two now\n",
      "Prediction: la e e t e eo\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 341s 758ms/step - loss: 67.5549 - val_loss: 63.2533 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 77ms/step- loss: 64.65\n",
      "Original: bin green at a seven soon\n",
      "Prediction: la e e i e ean\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place blue by j one again\n",
      "Prediction: la e e i e ean\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 339s 754ms/step - loss: 64.6578 - val_loss: 60.9750 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 71ms/step- loss: 62.66\n",
      "Original: set blue at h one again\n",
      "Prediction: la re t e eon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set green by j three again\n",
      "Prediction: la re t e eon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 342s 761ms/step - loss: 62.6635 - val_loss: 59.0271 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 113ms/step loss: 61.01\n",
      "Original: lay white with m one soon\n",
      "Prediction: la re t e ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set red in h three again\n",
      "Prediction: la re t e eo\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 380s 844ms/step - loss: 61.0110 - val_loss: 57.3628 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 77ms/step- loss: 59.40\n",
      "Original: set red with b nine soon\n",
      "Prediction: la re t e ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red with d seven again\n",
      "Prediction: la re t e aon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 362s 804ms/step - loss: 59.4057 - val_loss: 55.8885 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 75ms/step- loss: 57.94\n",
      "Original: set blue in t two now\n",
      "Prediction: la re t e ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set blue by n nine again\n",
      "Prediction: la re t e ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 363s 807ms/step - loss: 57.9484 - val_loss: 51.6873 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 76ms/step- loss: 54.44\n",
      "Original: lay white in r three soon\n",
      "Prediction: sit re t e ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set green at p two please\n",
      "Prediction: sit re t e ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 362s 806ms/step - loss: 54.4477 - val_loss: 51.2654 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 79ms/step- loss: 53.06\n",
      "Original: lay white in y nine again\n",
      "Prediction: la re i e ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red at sp p six please\n",
      "Prediction: la re t e ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 361s 804ms/step - loss: 53.0635 - val_loss: 49.4800 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 78ms/step- loss: 51.92\n",
      "Original: bin green by o one again\n",
      "Prediction: la re i ie aon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin white by t eight sp please\n",
      "Prediction: la re i ie ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 364s 809ms/step - loss: 51.9210 - val_loss: 48.2351 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 77ms/step- loss: 50.41\n",
      "Original: lay green with m seven soon\n",
      "Prediction: la re it ie ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin red sp by g two now\n",
      "Prediction: la re i oe ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 362s 805ms/step - loss: 50.4114 - val_loss: 46.0602 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 81ms/step- loss: 48.78\n",
      "Original: bin blue in r seven soon\n",
      "Prediction: la re it ie ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red with x seven soon\n",
      "Prediction: pla re it ie ao\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 364s 810ms/step - loss: 48.7867 - val_loss: 44.0937 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 73ms/step- loss: 47.02\n",
      "Original: place white in d one again\n",
      "Prediction: la re it ie aon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red at sp p seven again\n",
      "Prediction: la re it ie aon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 363s 808ms/step - loss: 47.0259 - val_loss: 42.8384 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 76ms/step- loss: 45.38\n",
      "Original: lay white by z four now\n",
      "Prediction: la re it ie ow\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place white in x three again\n",
      "Prediction: la re it ie aon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 350s 778ms/step - loss: 45.3806 - val_loss: 40.0828 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 74ms/step- loss: 43.77\n",
      "Original: lay red with f two please\n",
      "Prediction: pla re it oe plase\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay white at f zero please\n",
      "Prediction: pla re it oe plase\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 357s 794ms/step - loss: 43.7734 - val_loss: 38.7679 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 77ms/step- loss: 41.96\n",
      "Original: set white with v six now\n",
      "Prediction: la re it io now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set blue with b five again\n",
      "Prediction: la re it ie ain\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 791ms/step - loss: 41.9623 - val_loss: 36.7554 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 113ms/step loss: 40.34\n",
      "Original: bin blue at f four please\n",
      "Prediction: pla re it foe plas\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay red at e two now\n",
      "Prediction: sla re it wo now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 791ms/step - loss: 40.3441 - val_loss: 36.5421 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 71ms/step- loss: 38.36\n",
      "Original: lay green at s three soon\n",
      "Prediction: plac gre it soe son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set blue at n four please\n",
      "Prediction: la re it or please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 792ms/step - loss: 38.3692 - val_loss: 34.4937 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 74ms/step- loss: 35.98\n",
      "Original: set red with c one again\n",
      "Prediction: set wre it ie ain\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place blue by j zero please\n",
      "Prediction: place ble bt or plase\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 357s 794ms/step - loss: 35.9852 - val_loss: 30.1950 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 70ms/step- loss: 33.00\n",
      "Original: place white by y one again\n",
      "Prediction: plac whie by ie ain\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place green with z one again\n",
      "Prediction: place gre it ie ain\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 357s 793ms/step - loss: 33.0090 - val_loss: 26.8447 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 71ms/step- loss: 30.37\n",
      "Original: place red by x two now\n",
      "Prediction: place rie by wo now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay red with f one soon\n",
      "Prediction: lay re it oe son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 355s 790ms/step - loss: 30.3782 - val_loss: 24.8184 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 76ms/step- loss: 27.69\n",
      "Original: place white in p seven soon\n",
      "Prediction: place whie in ene son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set white by i five soon\n",
      "Prediction: set whte by fve son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 357s 793ms/step - loss: 27.6910 - val_loss: 22.5647 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 111ms/step loss: 25.73\n",
      "Original: place blue at v five again\n",
      "Prediction: place blue it five again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place white with k five soon\n",
      "Prediction: place white it five son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 792ms/step - loss: 25.7301 - val_loss: 20.8084 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 74ms/step- loss: 23.83\n",
      "Original: lay green in f one soon\n",
      "Prediction: lay gren in oe son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red by q one again\n",
      "Prediction: place re by ne again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 792ms/step - loss: 23.8365 - val_loss: 19.0382 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 71ms/step- loss: 22.46\n",
      "Original: place green at q seven soon\n",
      "Prediction: place gren at eve son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay blue with l zero please\n",
      "Prediction: lay blue it or please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 793ms/step - loss: 22.4635 - val_loss: 17.5129 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 80ms/step- loss: 20.94\n",
      "Original: bin white at n one again\n",
      "Prediction: bin white an ne again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay red at r three again\n",
      "Prediction: lay red it hre again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 791ms/step - loss: 20.9462 - val_loss: 16.0598 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 117ms/step loss: 19.60\n",
      "Original: bin white by h zero please\n",
      "Prediction: bin white by zor plese\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay blue with y eight please\n",
      "Prediction: lay blue ith ih please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 357s 793ms/step - loss: 19.6053 - val_loss: 14.7220 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 74ms/step- loss: 18.33\n",
      "Original: bin green with b four now\n",
      "Prediction: bin gren with for now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin white in g zero now\n",
      "Prediction: bin white in zo now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 357s 794ms/step - loss: 18.3359 - val_loss: 13.7877 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 74ms/step- loss: 17.40\n",
      "Original: lay red in y two please\n",
      "Prediction: lay red iy wo please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red in p three again\n",
      "Prediction: place red it tre again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 357s 794ms/step - loss: 17.4058 - val_loss: 13.0994 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 74ms/step- loss: 16.49\n",
      "Original: bin white in t one again\n",
      "Prediction: bin white in one again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place green with e seven soon\n",
      "Prediction: place gren ith seve son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 791ms/step - loss: 16.4902 - val_loss: 11.9036 - lr: 9.0484e-05\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 114ms/step loss: 15.53\n",
      "Original: lay red in e one again\n",
      "Prediction: lay red in one again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay red by r four now\n",
      "Prediction: lay red by for now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 356s 792ms/step - loss: 15.5321 - val_loss: 10.9409 - lr: 8.1873e-05\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 103680 values, but the requested shape has 311040 [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19320\\3614600779.py\", line 6, in load_data\n    frames = load_video(video_path)\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19320\\620157631.py\", line 6, in load_video\n    frame = tf.image.rgb_to_grayscale(frame)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 103680 values, but the requested shape has 311040 [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[CTCLoss/Shape_3/_4]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 103680 values, but the requested shape has 311040 [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19320\\3614600779.py\", line 6, in load_data\n    frames = load_video(video_path)\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19320\\620157631.py\", line 6, in load_video\n    frame = tf.image.rgb_to_grayscale(frame)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 103680 values, but the requested shape has 311040 [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_11493]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\bequiet\\model_training_v2.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/bequiet/model_training_v2.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train, validation_data\u001b[39m=\u001b[39;49mtest, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback, schedule_callback, example_callback])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 103680 values, but the requested shape has 311040 [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19320\\3614600779.py\", line 6, in load_data\n    frames = load_video(video_path)\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19320\\620157631.py\", line 6, in load_video\n    frame = tf.image.rgb_to_grayscale(frame)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 103680 values, but the requested shape has 311040 [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[CTCLoss/Shape_3/_4]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 103680 values, but the requested shape has 311040 [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19320\\3614600779.py\", line 6, in load_data\n    frames = load_video(video_path)\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19320\\620157631.py\", line 6, in load_video\n    frame = tf.image.rgb_to_grayscale(frame)\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 103680 values, but the requested shape has 311040 [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_11493]"
     ]
    }
   ],
   "source": [
    "model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lipnet01.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
